{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbaa230e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\shels\\anaconda3\\lib\\site-packages (1.12.1)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.15.2-cp310-cp310-win_amd64.whl (1.2 MB)\n",
      "     ---------------------------------------- 1.2/1.2 MB 8.5 MB/s eta 0:00:00\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.0.2-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "     ---------------------------------------- 2.1/2.1 MB 6.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\shels\\anaconda3\\lib\\site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\shels\\anaconda3\\lib\\site-packages (from torchvision) (1.23.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\shels\\anaconda3\\lib\\site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: requests in c:\\users\\shels\\anaconda3\\lib\\site-packages (from torchvision) (2.28.1)\n",
      "Collecting torch\n",
      "  Downloading torch-2.0.1-cp310-cp310-win_amd64.whl (172.3 MB)\n",
      "     -------------------------------------- 172.3/172.3 MB 5.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: sympy in c:\\users\\shels\\anaconda3\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\shels\\anaconda3\\lib\\site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\shels\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\shels\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\shels\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\shels\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shels\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\shels\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shels\\anaconda3\\lib\\site-packages (from requests->torchvision) (2023.5.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\shels\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.12.1\n",
      "    Uninstalling torch-1.12.1:\n",
      "      Successfully uninstalled torch-1.12.1\n",
      "Successfully installed torch-2.0.1 torchaudio-2.0.2 torchvision-0.15.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c75a0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.8.0.76-cp37-abi3-win_amd64.whl (38.1 MB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\shels\\anaconda3\\lib\\site-packages (from opencv-python) (1.23.5)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.8.0.76\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "771f156d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./image\\\\2092.jpg', './image\\\\3096.jpg', './image\\\\8023.jpg', './image\\\\8049.jpg']\n",
      "2092.jpg\n",
      "2092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shels\\AppData\\Local\\Temp\\ipykernel_17592\\2845161588.py:248: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  color_avg = [np.mean(img_flatten[im_target == label], axis=0, dtype=np.int) for label in un_label]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.236421585083008\n",
      "3.9499690532684326\n",
      "3.5543508529663086\n",
      "3.4661753177642822\n",
      "3.3348255157470703\n",
      "3.2197458744049072\n",
      "3.0893423557281494\n",
      "2.8283040523529053\n",
      "2.666529417037964\n",
      "2.4376163482666016\n",
      "2.176193952560425\n",
      "1.946478247642517\n",
      "1.7382181882858276\n",
      "1.602768898010254\n",
      "1.356461524963379\n",
      "1.1532115936279297\n",
      "1.00949227809906\n",
      "0.8441839814186096\n",
      "0.7273668050765991\n",
      "0.6311384439468384\n",
      "0.5430998206138611\n",
      "0.4696755111217499\n",
      "0.42865443229675293\n",
      "0.37329837679862976\n",
      "0.3386307954788208\n",
      "0.30652377009391785\n",
      "0.28334879875183105\n",
      "0.2598135471343994\n",
      "0.24384146928787231\n",
      "0.21849113702774048\n",
      "0.20901106297969818\n",
      "0.19355791807174683\n",
      "0.18376274406909943\n",
      "0.1745016872882843\n",
      "0.16521711647510529\n",
      "0.15716980397701263\n",
      "0.14975884556770325\n",
      "0.1427249312400818\n",
      "0.13617895543575287\n",
      "0.1307094693183899\n",
      "0.12464424967765808\n",
      "0.1211596205830574\n",
      "0.11571159958839417\n",
      "0.11194487661123276\n",
      "0.10898508876562119\n",
      "0.10478020459413528\n",
      "0.10226966440677643\n",
      "0.09899264574050903\n",
      "0.09647420793771744\n",
      "0.09364181011915207\n",
      "0.09114713966846466\n",
      "0.08890943974256516\n",
      "0.08636625856161118\n",
      "0.08440886437892914\n",
      "0.08223826438188553\n",
      "0.08026661723852158\n",
      "0.07919234037399292\n",
      "0.08018173277378082\n",
      "0.09801999479532242\n",
      "0.18512608110904694\n",
      "0.10077767819166183\n",
      "0.12904635071754456\n",
      "0.1414288431406021\n",
      "0.10840547829866409\n",
      "0.11024713516235352\n",
      "0.1028689295053482\n",
      "0.10425204038619995\n",
      "0.10286460816860199\n",
      "0.10123948752880096\n",
      "0.09908486902713776\n",
      "0.095821313560009\n",
      "0.09237287938594818\n",
      "0.09072688221931458\n",
      "0.08747565746307373\n",
      "0.08348554372787476\n",
      "0.08269043266773224\n",
      "0.08021165430545807\n",
      "0.07792974263429642\n",
      "0.07563752681016922\n",
      "0.07436030358076096\n",
      "0.07211323082447052\n",
      "0.07079558819532394\n",
      "0.06947991997003555\n",
      "0.06802046298980713\n",
      "0.06620626151561737\n",
      "0.0653064176440239\n",
      "0.06351694464683533\n",
      "0.06244020536541939\n",
      "0.06132376194000244\n",
      "0.06019799783825874\n",
      "0.05912033095955849\n",
      "0.057662688195705414\n",
      "0.05674269050359726\n",
      "0.05563223734498024\n",
      "0.05457847937941551\n",
      "0.05348752439022064\n",
      "0.05241802707314491\n",
      "0.05146137252449989\n",
      "0.050484105944633484\n",
      "0.04948779568076134\n",
      "PyTorchInit: 399.33\n",
      "TimeUsed: 399.11\n",
      "399.10997557640076\n",
      "3096.jpg\n",
      "3096\n",
      "4.291801452636719\n",
      "4.17589807510376\n",
      "4.054367542266846\n",
      "4.0721025466918945\n",
      "3.812863826751709\n",
      "3.723879814147949\n",
      "3.6230475902557373\n",
      "3.44990873336792\n",
      "3.2600042819976807\n",
      "3.093310832977295\n",
      "2.8923020362854004\n",
      "2.675630807876587\n",
      "2.4569878578186035\n",
      "2.240074396133423\n",
      "2.021254539489746\n",
      "1.8261877298355103\n",
      "1.6165590286254883\n",
      "1.401476263999939\n",
      "1.2067242860794067\n",
      "0.9641666412353516\n",
      "0.7789551019668579\n",
      "0.6314727663993835\n",
      "0.5143559575080872\n",
      "0.42425400018692017\n",
      "0.35398152470588684\n",
      "0.300443559885025\n",
      "0.262652188539505\n",
      "0.23083341121673584\n",
      "0.20779232680797577\n",
      "0.1896096169948578\n",
      "0.17505520582199097\n",
      "0.16232116520404816\n",
      "0.149438738822937\n",
      "0.13772162795066833\n",
      "0.1274445354938507\n",
      "0.11845839023590088\n",
      "0.1108831837773323\n",
      "0.10324113816022873\n",
      "0.09788317233324051\n",
      "0.09081953763961792\n",
      "0.08641678094863892\n",
      "0.0835619568824768\n",
      "0.08015312254428864\n",
      "0.07584778964519501\n",
      "0.07328851521015167\n",
      "0.06855057924985886\n",
      "0.06422701478004456\n",
      "0.06118471547961235\n",
      "0.05841224640607834\n",
      "0.05636374279856682\n",
      "0.05404464900493622\n",
      "0.051940687000751495\n",
      "0.05018030107021332\n",
      "0.048198964446783066\n",
      "0.046486709266901016\n",
      "0.04503018409013748\n",
      "0.043856050819158554\n",
      "0.04274660348892212\n",
      "0.0417424812912941\n",
      "0.04044719412922859\n",
      "0.03962758556008339\n",
      "0.03889547288417816\n",
      "0.03885433450341225\n",
      "0.03780340403318405\n",
      "0.038802750408649445\n",
      "0.03631666675209999\n",
      "0.03645527735352516\n",
      "0.03516295924782753\n",
      "0.03574603423476219\n",
      "0.03421976417303085\n",
      "0.03460206836462021\n",
      "0.03326691687107086\n",
      "0.033758725970983505\n",
      "0.03248248249292374\n",
      "0.03243706747889519\n",
      "0.03177535906434059\n",
      "0.031226851046085358\n",
      "0.030948253348469734\n",
      "0.030501773580908775\n",
      "0.029990561306476593\n",
      "0.029823902994394302\n",
      "0.029621414840221405\n",
      "0.029568251222372055\n",
      "0.028930967673659325\n",
      "0.028862304985523224\n",
      "0.02812076359987259\n",
      "0.02800123021006584\n",
      "0.027688486501574516\n",
      "0.02742806077003479\n",
      "0.0271612461656332\n",
      "0.026648174971342087\n",
      "0.026621907949447632\n",
      "0.026950698345899582\n",
      "0.02822551503777504\n",
      "0.02899976260960102\n",
      "0.026039011776447296\n",
      "0.030720794573426247\n",
      "0.033836543560028076\n",
      "0.03236251324415207\n",
      "0.02931007742881775\n",
      "PyTorchInit: 294.71\n",
      "TimeUsed: 294.52\n",
      "294.5208144187927\n",
      "8023.jpg\n",
      "8023\n",
      "4.331352710723877\n",
      "3.9115190505981445\n",
      "3.6703009605407715\n",
      "3.463226079940796\n",
      "3.2670681476593018\n",
      "3.0956437587738037\n",
      "2.9395012855529785\n",
      "2.7969236373901367\n",
      "2.6016526222229004\n",
      "2.403507709503174\n",
      "2.2235541343688965\n",
      "2.0352368354797363\n",
      "1.8614227771759033\n",
      "1.7072452306747437\n",
      "1.549169659614563\n",
      "1.3986756801605225\n",
      "1.277880072593689\n",
      "1.1941609382629395\n",
      "1.1283793449401855\n",
      "0.9824737906455994\n",
      "0.9183314442634583\n",
      "0.8138273358345032\n",
      "0.7418209314346313\n",
      "0.6990800499916077\n",
      "0.6225990056991577\n",
      "0.5805600881576538\n",
      "0.5447826385498047\n",
      "0.4967855215072632\n",
      "0.4690777659416199\n",
      "0.45378556847572327\n",
      "0.5102097988128662\n",
      "0.5720259547233582\n",
      "0.5480130314826965\n",
      "0.47263896465301514\n",
      "0.4445474445819855\n",
      "0.42623838782310486\n",
      "0.3983924388885498\n",
      "0.39075466990470886\n",
      "0.3569542169570923\n",
      "0.34783780574798584\n",
      "0.3218107521533966\n",
      "0.3169938027858734\n",
      "0.29595378041267395\n",
      "0.28998133540153503\n",
      "0.2698739767074585\n",
      "0.2625178098678589\n",
      "0.25233346223831177\n",
      "0.2482033669948578\n",
      "0.23506036400794983\n",
      "0.22628913819789886\n",
      "0.21960249543190002\n",
      "0.2100570797920227\n",
      "0.2032875120639801\n",
      "0.19457662105560303\n",
      "0.18769657611846924\n",
      "0.18130268156528473\n",
      "0.17456229031085968\n",
      "0.16882425546646118\n",
      "0.1640232503414154\n",
      "0.15893413126468658\n",
      "0.1592894196510315\n",
      "0.1934412568807602\n",
      "0.17417779564857483\n",
      "0.15282757580280304\n",
      "0.14970144629478455\n",
      "0.1442636102437973\n",
      "0.13792172074317932\n",
      "0.13887858390808105\n",
      "0.12523145973682404\n",
      "0.13032780587673187\n",
      "0.1292932778596878\n",
      "0.11619693785905838\n",
      "0.1286693662405014\n",
      "0.15003690123558044\n",
      "0.11549340188503265\n",
      "0.13751526176929474\n",
      "0.12055932730436325\n",
      "0.1261480301618576\n",
      "0.10985478013753891\n",
      "0.10889346152544022\n",
      "0.1064392700791359\n",
      "0.09674107283353806\n",
      "0.09808743745088577\n",
      "0.08871080726385117\n",
      "0.08944031596183777\n",
      "0.08724147081375122\n",
      "0.08458811789751053\n",
      "0.08260375261306763\n",
      "0.07210236042737961\n",
      "0.07764938473701477\n",
      "0.07558240741491318\n",
      "0.0796528160572052\n",
      "0.07429856061935425\n",
      "0.07218671590089798\n",
      "0.0633428618311882\n",
      "0.05971398949623108\n",
      "0.058764636516571045\n",
      "0.05746252462267876\n",
      "0.05373505875468254\n",
      "0.0530737079679966\n",
      "PyTorchInit: 283.60\n",
      "TimeUsed: 283.46\n",
      "283.4634282588959\n",
      "3.256980727513631\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage import segmentation\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.modules.batchnorm import _BatchNorm\n",
    "import torch.nn.functional as F\n",
    "from scipy.io import loadmat,savemat\n",
    "from unet_model import *\n",
    "\n",
    "mark_boundaries = segmentation.mark_boundaries\n",
    "\n",
    "def denormalizeimage(images, mean=(0., 0., 0.), std=(1., 1., 1.)):\n",
    "    \"\"\"Denormalize tensor images with mean and standard deviation.\n",
    "    Args:\n",
    "        images (tensor): N*C*H*W\n",
    "        mean (tuple): means for each channel.\n",
    "        std (tuple): standard deviations for each channel.\n",
    "    \"\"\"\n",
    "    images = images.cpu().numpy()\n",
    "    # N*C*H*W to N*H*W*C\n",
    "    images = images.transpose((0,2,3,1))\n",
    "    images *= std\n",
    "    images += mean\n",
    "    images *=255.0\n",
    "    # N*H*W*C to N*C*H*W\n",
    "    images = images.transpose((0,3,1,2))\n",
    "    return torch.tensor(images)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, inp_dim, mod_dim1, mod_dim2):\n",
    "        super(UNet, self).__init__()\n",
    "        self.inc = inconv(inp_dim, 64)\n",
    "        self.down1 = down(64, 128)\n",
    "        self.up4 = up(192, 128)\n",
    "        self.dcs0 = DCS(128, 32, 3)\n",
    "        self.outc = outconv(128, mod_dim2)\n",
    "        self.dcs1 = DCS(mod_dim2, 32, 3)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x = self.up4(x2, x1)\n",
    "        x = self.outc(x)\n",
    "        x, mu = self.dcs1(x)\n",
    "        return x\n",
    "\n",
    "class DCS(nn.Module):\n",
    "    '''The Deep Clustering Subnetwork (DCS).\n",
    "    Arguments:\n",
    "        c (int): The input and output channel number.\n",
    "        k (int): The number of cluster centers.\n",
    "        stage_num (int): The iteration number for EM.\n",
    "    '''\n",
    "    ### 定义DCS网络结构\n",
    "    def __init__(self, c, k, stage_num=3):\n",
    "        super(DCS, self).__init__()\n",
    "        self.stage_num = stage_num\n",
    "\n",
    "        mu = torch.Tensor(1, c, k)  #\n",
    "        mu.normal_(0, math.sqrt(2. / k))  #\n",
    "        mu = self._l2norm(mu, dim=1)\n",
    "        self.register_buffer('mu', mu)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(c, c, 1)\n",
    "        self.conv2 =nn.Conv2d(c, c, 1, bias=False)\n",
    "\n",
    "        ####iteration\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, _BatchNorm):\n",
    "                m.weight.data.fill_(1)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        idn = x\n",
    "        # The first 1x1 conv\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        b, c, h, w = x.size()\n",
    "        x = x.view(b, c, h * w)\n",
    "        mu = self.mu.repeat(b, 1, 1)  # b * c * k\n",
    "        with torch.no_grad():\n",
    "            for i in range(self.stage_num):\n",
    "                x_t = x.permute(0, 2, 1)  # b * n * c\n",
    "                z = torch.bmm(x_t, mu)  # b * n * k\n",
    "                z = F.softmax(z, dim=2)  # b * n * k\n",
    "                z_ = z / (1e-6 + z.sum(dim=1, keepdim=True))\n",
    "                mu = torch.bmm(x, z_)\n",
    "                mu = self._l2norm(mu, dim=1)\n",
    "\n",
    "        z_t = z.permute(0, 2, 1)  # b * k * n\n",
    "        x = mu.matmul(z_t)  # b * c * n\n",
    "        x = x.view(b, c, h, w)  # b * c * h * w\n",
    "        x = F.relu(x, inplace=True)\n",
    "\n",
    "        # The second 1x1 conv\n",
    "        x = self.conv2(x)\n",
    "        x = x + idn #\n",
    "        x = F.relu(x, inplace=True)\n",
    "\n",
    "        return x, mu\n",
    "\n",
    "    def _l2norm(self, inp, dim):\n",
    "        '''Normlize the inp tensor with l2-norm.\n",
    "\n",
    "        Returns a tensor where each sub-tensor of input along the given dim is\n",
    "        normalized such that the 2-norm of the sub-tensor is equal to 1.\n",
    "\n",
    "        Arguments:\n",
    "            inp (tensor): The inp\n",
    "            ut tensor.\n",
    "            dim (int): The dimension to slice over to get the ssub-tensors.\n",
    "\n",
    "        Returns:\n",
    "            (tensor) The normalized tensor.\n",
    "        '''\n",
    "        return inp / (1e-6 + inp.norm(dim=dim, keepdim=True))\n",
    "\n",
    "class Args(object):\n",
    "    train_epoch =100 ## training iteration T ##\n",
    "    mod_dim1 = 64  #\n",
    "    mod_dim2 =100 #\n",
    "    gpu_id =0 #0\n",
    "    min_label_num = 4  # if the label number small than it, break loop\n",
    "    max_label_num = 256  # if the label number small than it, start to show result image.\n",
    "\n",
    "\n",
    "class MyNet(nn.Module):\n",
    "    def __init__(self, inp_dim, mod_dim1, mod_dim2):\n",
    "        super(MyNet, self).__init__()\n",
    "\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Conv2d(inp_dim, mod_dim1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(mod_dim1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mod_dim1, mod_dim2, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(mod_dim2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mod_dim2, mod_dim1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(mod_dim1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mod_dim1, mod_dim2, kernel_size=1, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(mod_dim2),\n",
    "        )\n",
    "        self.emau = DCS(mod_dim2, 64, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=self.seq(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def get_filelist(dir, Filelist):\n",
    "\n",
    "    newDir = dir\n",
    "\n",
    "    if os.path.isfile(dir):\n",
    "\n",
    "        Filelist.append(dir)\n",
    "\n",
    "    elif os.path.isdir(dir):\n",
    "        for s in os.listdir(dir):\n",
    "            newDir = os.path.join(dir, s)\n",
    "            get_filelist(newDir, Filelist)\n",
    "\n",
    "    return Filelist\n",
    "\n",
    "\n",
    "def run(name,namep):\n",
    "    start_time0 = time.time()\n",
    "    args = Args()\n",
    "    pathbsd='./image\\\\'\n",
    "    torch.cuda.manual_seed_all(1943)\n",
    "    np.random.seed(1943)\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = str(args.gpu_id)  # choose GPU:0\n",
    "    input_image_path = pathbsd + name\n",
    "    image = cv2.imread(input_image_path)\n",
    "\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    '''segmentation ML'''\n",
    "    m = loadmat('./superpixel/'+namep+'.mat');\n",
    "    seglab = m[\"seg_lab\"]\n",
    "\n",
    "    seg_map=seglab\n",
    "    show = mark_boundaries(image, seg_map)\n",
    "    seg_map = seg_map.flatten()\n",
    "    seg_lab = [np.where(seg_map == u_label)[0]\n",
    "               for u_label in np.unique(seg_map)]\n",
    "\n",
    "    '''train init'''\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    tensor = image.transpose((2, 0, 1))\n",
    "    tensor = tensor.astype(np.float32) / 255.0\n",
    "    tensor = tensor[np.newaxis, :, :, :]\n",
    "    tensor = torch.from_numpy(tensor).to(device)\n",
    "    model = UNet(inp_dim=3, mod_dim1=args.mod_dim1, mod_dim2=args.mod_dim2).to(device)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=5e-2, momentum=0.9)\n",
    "    image_flatten = image.reshape((-1, 3))\n",
    "    color_avg = np.random.randint(255, size=(args.max_label_num, 3))\n",
    "    show = image\n",
    "\n",
    "    '''train loop'''\n",
    "    start_time1 = time.time()\n",
    "    model.train()\n",
    "    for batch_idx in range(args.train_epoch):\n",
    "        '''forward'''\n",
    "        optimizer.zero_grad()\n",
    "        output = model(tensor)[0]\n",
    "        output1=output\n",
    "        output1 = output1[np.newaxis, :, :, :]\n",
    "        output2= output[0:1, :, :]\n",
    "        croppings = (output2 > 0).float()\n",
    "\n",
    "        output = output.permute(1, 2, 0).view(-1, args.mod_dim2)\n",
    "        target = torch.argmax(output, 1)\n",
    "        im_target = target.data.cpu().numpy()\n",
    "\n",
    "        '''refine'''\n",
    "        for inds in seg_lab:\n",
    "            u_labels, hist = np.unique(im_target[inds], return_counts=True)\n",
    "            im_target[inds] = u_labels[np.argmax(hist)]\n",
    "\n",
    "        '''backward'''\n",
    "        target = torch.from_numpy(im_target)\n",
    "        target = target.to(device)\n",
    "\n",
    "        loss = criterion(output, target) #as defined in Eq. (8)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        '''show image''' #to print using the pesudo color;\n",
    "        un_label, lab_inverse = np.unique(im_target, return_inverse=True, )\n",
    "        if un_label.shape[0] < args.max_label_num:  # update show\n",
    "            img_flatten = image_flatten.copy()\n",
    "            if len(color_avg) != un_label.shape[0]:\n",
    "                color_avg = [np.mean(img_flatten[im_target == label], axis=0, dtype=np.int) for label in un_label]\n",
    "            for lab_id, color in enumerate(color_avg):\n",
    "                img_flatten[lab_inverse == lab_id] = color\n",
    "            show = img_flatten.reshape(image.shape)\n",
    "        cv2.imshow(\"seg_pt\", show)\n",
    "        cv2.waitKey(1)\n",
    "        print(loss.item())\n",
    "        if len(un_label) < args.min_label_num:\n",
    "            break\n",
    "\n",
    "    '''save'''\n",
    "    sp=list(image.shape)\n",
    "    label = im_target.reshape((sp[0],sp[1]))\n",
    "\n",
    "    time0 = time.time() - start_time0\n",
    "    time1 = time.time() - start_time1\n",
    "\n",
    "    print('PyTorchInit: %.2f\\nTimeUsed: %.2f' % (time0, time1))\n",
    "    cv2.imwrite(\"output/seg_%s_%ds.jpg\" % (namep, time1), show)\n",
    "    return time1\n",
    "\n",
    "def mainf():\n",
    "    dir='./image\\\\'\n",
    "    LIst=get_filelist(dir, [])\n",
    "    print(LIst)\n",
    "    ST=0\n",
    "    for ii in range(len(LIst)-1):\n",
    "        name=LIst[ii][8:]\n",
    "        print(name)\n",
    "        namep=name[:-4]\n",
    "        print(namep)\n",
    "        time=run(name,namep)\n",
    "        print(time)\n",
    "        ST=ST+time\n",
    "    print(ST/300)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #run()\n",
    "    mainf()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c540e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
